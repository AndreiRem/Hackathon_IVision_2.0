{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_count(input_file):\n",
    "    video = cv2.VideoCapture(input_file)\n",
    "    frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(input_file, output_dir, frames_list, prefix):\n",
    "    video = cv2.VideoCapture(input_file)\n",
    "    for i in frames_list:\n",
    "        video.set(1, i)\n",
    "        retval, image = video.read()\n",
    "        if retval:\n",
    "            cv2.imwrite(f'{output_dir}{prefix}-{i}.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(input_list):\n",
    "    train = input_list[:int(len(input_list)*0.6)]\n",
    "    test = input_list[-int(len(input_list)*0.1):]\n",
    "    val = input_list[-int(len(input_list)*0.3):]\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frames_list(n, max_n, step_treshold, start, end, endpoint=False):\n",
    "        while n < max_n:\n",
    "            frames_range, step = np.linspace(start, end, num=n, endpoint=endpoint, dtype=int, retstep=True)\n",
    "            if step < step_treshold: break\n",
    "            n += 1\n",
    "        return frames_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.set_index('video', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"kaggle_archive.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "os.rename(\"data\", \"dataset\")\n",
    "\n",
    "with zipfile.ZipFile(\"videos.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes = data[data['crash_happened'] == 1].index.values\n",
    "no_crashes = data[data['crash_happened'] == 0].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_train, crash_test, crash_val = split_list(crashes)\n",
    "no_crash_train, no_crash_test, no_crash_val = split_list(no_crashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [05:12<00:06,  6.36s/it]"
     ]
    }
   ],
   "source": [
    "# Видео лежат в папке dataset/videos\n",
    "\n",
    "skip_videos = (1, 3)\n",
    "train = ()\n",
    "\n",
    "for i in tqdm.tqdm(range(1, 51)):\n",
    "    if i in skip_videos: continue\n",
    "    \n",
    "    if (i in crash_train) or (i in no_crash_train):\n",
    "        path = f'dataset/train/'\n",
    "    elif (i in crash_test) or (i in no_crash_test):\n",
    "        path = f'dataset/test/'\n",
    "    else:\n",
    "        path = f'dataset/val/'\n",
    "        \n",
    "    video_data = data[data.index == i]\n",
    "    crash = bool(video_data['crash_happened'].values)\n",
    "    \n",
    "    if crash:\n",
    "        \n",
    "        crash_start = int(video_data['crash_start'].values)\n",
    "        \n",
    "        # Начало столкновения - берем первые 10 кадров, т.к. самая динамическая часть\n",
    "        frames_list = list(range(crash_start, crash_start + 10))\n",
    "        get_frames(f'dataset/videos/{i}.mp4', f'{path}Accident/', frames_list, i)\n",
    "        \n",
    "        # Генерируем следующий набор кадров\n",
    "        # Минимум - 10 кадров, максимум - 40 кадров\n",
    "        # Минимальный шаг между кадрами - 15 кадров\n",
    "        frames_list = generate_frames_list(10, 40, 15, crash_start + 10, int(video_data['collision_end'].values), endpoint=True)\n",
    "        get_frames(f'dataset/videos/{i}.mp4', f'{path}Accident/', frames_list, i)\n",
    "        \n",
    "        # Переносим кадры без столкновения, если они есть\n",
    "        if crash_start > 0:\n",
    "            # Генерируем набор кадров\n",
    "            # Максимум - 50 кадров, минимум - 25 кадров\n",
    "            # Минимальный шаг между кадрами - 15 кадров\n",
    "            frames_list = generate_frames_list(25, 50, 15, 0, crash_start)\n",
    "            get_frames(f'dataset/videos/{i}.mp4', f'{path}Non Accident/', frames_list, i)\n",
    "\n",
    "    # Если ДТП в видео отсутствует\n",
    "    else:\n",
    "        frames_list = generate_frames_list(25, 50, 15, 0, int(video_data['video_end'].values))\n",
    "        get_frames(f'dataset/videos/{i}.mp4', f'{path}Non Accident/', frames_list, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
